[
  {
    "objectID": "lab06.html",
    "href": "lab06.html",
    "title": "ess-330-lab06",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org/\"))\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\ninstall.packages(\"powerjoin\")\n\n\nThe downloaded binary packages are in\n    /var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//RtmprarCNN/downloaded_packages\n\nlibrary(powerjoin)\ninstall.packages(\"glue\")\n\n\nThe downloaded binary packages are in\n    /var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//RtmprarCNN/downloaded_packages\n\nlibrary(glue)\ninstall.packages(\"vip\")\n\n\nThe downloaded binary packages are in\n    /var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//RtmprarCNN/downloaded_packages\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\ninstall.packages(\"baguette\")\n\n\nThe downloaded binary packages are in\n    /var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//RtmprarCNN/downloaded_packages\n\nlibrary(baguette)\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\n\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\nlocal_files   &lt;- glue('data/camels_{types}.txt')\n\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')"
  },
  {
    "objectID": "lab06.html#my-turn",
    "href": "lab06.html#my-turn",
    "title": "ess-330-lab06",
    "section": "My Turn!",
    "text": "My Turn!\n\ninstall.packages(\"xgboost\")\n\n\nThe downloaded binary packages are in\n    /var/folders/jn/hk4fnzlx679cs3m0_lnzh7hh0000gn/T//RtmprarCNN/downloaded_packages\n\nlibrary(xgboost)\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nxg_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\") \n\nxg_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(xg_model) %&gt;%\n  fit(data = camels_train)\n\nnn_model &lt;- mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\") \n\nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(nn_model) %&gt;%\n  fit(data = camels_train)\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model, xg_model, nn_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\nrank_results(wf, rank_metric = \"rsq\", select_best = TRUE)\n\n# A tibble: 8 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 recipe_mlp        Prepro… rmse    0.565  0.0312    10 recipe       mlp       1\n2 recipe_mlp        Prepro… rsq     0.762  0.0282    10 recipe       mlp       1\n3 recipe_linear_reg Prepro… rmse    0.601  0.0350    10 recipe       line…     2\n4 recipe_linear_reg Prepro… rsq     0.737  0.0302    10 recipe       line…     2\n5 recipe_rand_fore… Prepro… rmse    0.601  0.0320    10 recipe       rand…     3\n6 recipe_rand_fore… Prepro… rsq     0.737  0.0302    10 recipe       rand…     3\n7 recipe_boost_tree Prepro… rmse    0.634  0.0294    10 recipe       boos…     4\n8 recipe_boost_tree Prepro… rsq     0.715  0.0275    10 recipe       boos…     4\n\n\nAfter evaluating the models and comparing them, I would choose to move forward with the neural network model. It’s rsq was the highest of the four and it had the lowest rmse, indicating that it is the most effective model."
  }
]